# Models

Place **.gguf** models here for offline use with llama.cpp.

⚠️ Do not version models on GitHub.

## Recommended
- TinyLlama 1.1B (Q4)
- Phi-2 (Q4)
- Qwen 1.5B (Q4)

Rename the active model to:
